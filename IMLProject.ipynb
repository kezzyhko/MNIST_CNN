{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMLProject",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lohPUbbI2eUp"
      },
      "source": [
        "# Preparing\n",
        "Run once when disconnected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBg1WuyjgG9R"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GaussianNoise, BatchNormalization\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVkWTWOngbQJ"
      },
      "source": [
        "# # download the dataset\n",
        "# if (not os.path.isfile('x.npy')):\n",
        "#     !wget -q https://gist.github.com/kezzyhko/74136f15acb0ac57e64a761176776ab0/raw/x.npy\n",
        "# if (not os.path.isfile('y.npy')):\n",
        "#     !wget -q https://gist.github.com/kezzyhko/74136f15acb0ac57e64a761176776ab0/raw/y.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYjwZxnEiHQo"
      },
      "source": [
        "# load the dataset\n",
        "\n",
        "(mnist_X_train, mnist_y_train), (mnist_X_test, mnist_y_test) = tf.keras.datasets.mnist.load_data()\n",
        "mnist_X_train = mnist_X_train.reshape((60000, 28, 28, 1))\n",
        "mnist_X_test = mnist_X_test.reshape((10000, 28, 28, 1))\n",
        "\n",
        "x = np.concatenate((mnist_X_train, mnist_X_test), axis=0)\n",
        "y = np.concatenate((mnist_y_train, mnist_y_test), axis=0)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-qdGb6vg0-h"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCe3NTZ7PI7"
      },
      "source": [
        "# # plt.imshow(x[0].reshape(28, 28)/255., cmap='Greys')\n",
        "# g = GaussianNoise(70)\n",
        "# x = g(x.astype('float32'), training=True)\n",
        "# plt.imshow(tf.reshape(x[0], (28, 28))/255., cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI6WPOsHg8dJ"
      },
      "source": [
        "generator = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.1,\n",
        "    zoom_range = (0.9, 2),\n",
        "    shear_range = 10,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJG9W7iv0Y6S"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(tf.reshape(x[i], (28, 28)), cmap=plt.cm.binary)\n",
        "    plt.xlabel(y[i])\n",
        "plt.show()\n",
        "\n",
        "print('---')\n",
        "\n",
        "for x1, y1 in generator.flow(x, y, batch_size = 25):\n",
        "   plt.figure(figsize=(10,10))\n",
        "   for i in range(25):\n",
        "       plt.subplot(5,5,i+1)\n",
        "       plt.xticks([])\n",
        "       plt.yticks([])\n",
        "       plt.grid(False)\n",
        "       plt.imshow(x1[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "       plt.xlabel(y1[i])\n",
        "   plt.show()\n",
        "   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJS7VPzy2ikc"
      },
      "source": [
        "# The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFEW_1RzmFEd"
      },
      "source": [
        "## Make the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtDWSWYUgcgx"
      },
      "source": [
        "# create the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GaussianNoise(70, input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides = 2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides = 2))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=[Recall(), Precision()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6XJbhyNiQ-W"
      },
      "source": [
        "# train the model\n",
        "# model.fit(x, to_categorical(y), validation_split=0.15)\n",
        "model.fit(\n",
        "    generator.flow(x, to_categorical(y), batch_size = 128),\n",
        "    validation_data = generator.flow(x, to_categorical(y), batch_size = 128, subset = 'validation'),\n",
        "    steps_per_epoch = len(x) / 128,\n",
        "    epochs = 15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avhD_RgJl9uX"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrBUsInXiVxl"
      },
      "source": [
        "# save the model\n",
        "model.save('model.h5')\n",
        "zipfile.ZipFile('model.h5.zip', mode='w').write(\"model.h5\")\n",
        "print(os.path.getsize(\"/content/model.h5.zip\") / (1024*1024))\n",
        "files.download('model.h5.zip') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdzC1J6AlzXq"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTSuo3Wjk0jp"
      },
      "source": [
        "# make the prediction\n",
        "y_pred = model.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bgJC_aa5Wmr"
      },
      "source": [
        "# transform prediction to labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4wH0P3ciaLQ"
      },
      "source": [
        "# evaluate performance of the model\n",
        "tf.print(f1_score(y_pred_labels, y, average='micro'))\n",
        "tf.print(f1_score(y_pred_labels, y, average='macro'))\n",
        "tf.print(f1_score(y_pred_labels, y, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}